{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the final database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step's aim is to generate the final database that we're going to use to train our model. This database contains the features of both interacting proteins concatenated into one line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from dotenv.main import load_dotenv\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the DB API info from the .env file\n",
    "load_dotenv()\n",
    "URI = urlparse(os.getenv(\"DB_URI\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the the two datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to read the two seperated datasets and clean them by removing self-interacting proteins, then the Refseq ID of each interactor is used to find the corresponding AA sequence which is then used to query the Render DB for the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the data from the two csv files...\n",
      "Reading done!\n"
     ]
    }
   ],
   "source": [
    "# read the data from the two csv files\n",
    "print(\"Reading the data from the two csv files...\")\n",
    "df1 = pd.read_csv(\"../data/data1.csv\")\n",
    "df2 = pd.read_csv(\"../data/data2.csv\")\n",
    "print(\"Reading done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing the lines where Interactor A is the same as Interactor B...\n",
      "Removed 2160 lines from data1.csv\n",
      "Removed 0 lines from data2.csv\n"
     ]
    }
   ],
   "source": [
    "# remove the lines where Interactor A is the same as Interactor B\n",
    "print(\"Removing the lines where Interactor A is the same as Interactor B...\")\n",
    "data1_old_size = df1.shape[0]\n",
    "data2_old_size = df2.shape[0]\n",
    "\n",
    "df1 = df1[df1[\"Interactor A\"] != df1[\"Interactor B\"]]\n",
    "df2 = df2[df2[\"Interactor A\"] != df2[\"Interactor B\"]]\n",
    "\n",
    "data1_new_size = df1.shape[0]\n",
    "data2_new_size = df2.shape[0]\n",
    "\n",
    "print(\"Removed {} lines from data1.csv\".format(data1_old_size - data1_new_size))\n",
    "print(\"Removed {} lines from data2.csv\".format(data2_old_size - data2_new_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating the two dataframes...\n",
      "Concatenation done!\n",
      "Saving the dataframe as a csv file...\n",
      "Saving done!\n"
     ]
    }
   ],
   "source": [
    "# concatenate the two dataframes\n",
    "print(\"Concatenating the two dataframes...\")\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "print(\"Concatenation done!\")\n",
    "\n",
    "# save the dataframe as a csv file\n",
    "print(\"Saving the dataframe as a csv file...\")\n",
    "df.to_csv(\"../data/data_conc.csv\", index=False)\n",
    "print(\"Saving done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataframe: 2551888\n"
     ]
    }
   ],
   "source": [
    "# print the new size of the dataframe\n",
    "print(f\"Number of rows in the dataframe: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the dataframe as a csv file...\n"
     ]
    }
   ],
   "source": [
    "# limit the dataframe df to the first 100000 rows because HOLY SHIT IT'S TAKING TOO LONG!!!\n",
    "df = df.iloc[:100000, :]\n",
    "\n",
    "# save the dataframe as a csv file\n",
    "print(\"Saving the dataframe as a csv file...\")\n",
    "df.to_csv(\"../data/data_conc_100k.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10277\n"
     ]
    }
   ],
   "source": [
    "# sequences dic\n",
    "sequences = {}\n",
    "\n",
    "# read two lines from the sequences.fasta file at a time\n",
    "with open(\"../dbs/generated/sequences.fasta\", \"r\") as f:\n",
    "    for id, seq in itertools.zip_longest(*[f]*2):\n",
    "        id = id.strip()[1:]\n",
    "        seq = seq.strip()\n",
    "        sequences[id] = seq\n",
    "\n",
    "# print the length of the dictionary\n",
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new dataframe with two columns: Interactor A and Interactor B...\n",
      "Reading the dictionary containing the 100k examples...\n"
     ]
    }
   ],
   "source": [
    "# create a new dataframe with two columns: Interactor A and Interactor B, this time the values are going to be AA sequences instead of RefSeq IDs\n",
    "print(\"Creating a new dataframe with two columns: Interactor A and Interactor B...\")\n",
    "df_new = pd.DataFrame(columns=[\"Interactor A\", \"Interactor B\"])\n",
    "\n",
    "# read the dictionary containing the 100k examples\n",
    "print(\"Reading the dictionary containing the 100k examples...\")\n",
    "df = pd.read_csv(\"../data/data_conc_100k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each row in the dataframe, get the AA sequence of Interactor A and Interactor B...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\elaty\\AppData\\Local\\Programs\\Venvs\\main\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:164\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 164\u001b[0m     result \u001b[39m=\u001b[39m func(left, right)\n\u001b[0;32m    165\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\elaty\\AppData\\Local\\Programs\\Venvs\\main\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    238\u001b[0m         \u001b[39m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m         \u001b[39mreturn\u001b[39;00m _evaluate(op, op_str, a, b)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32mc:\\Users\\elaty\\AppData\\Local\\Programs\\Venvs\\main\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:70\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     69\u001b[0m     _store_test_result(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m op(a, b)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m         seq_b \u001b[39m=\u001b[39m sequences[interactor_b]\n\u001b[0;32m     14\u001b[0m         \u001b[39m# add the row to the new dataframe\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m         df_new \u001b[39m-\u001b[39;49m pd\u001b[39m.\u001b[39;49mconcat([df_new, pd\u001b[39m.\u001b[39;49mDataFrame([[seq_a, seq_b]], columns\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mInteractor A\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mInteractor B\u001b[39;49m\u001b[39m\"\u001b[39;49m])])\n\u001b[0;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[39m# print the shape of the new dataframe\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\elaty\\AppData\\Local\\Programs\\Venvs\\main\\lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32mc:\\Users\\elaty\\AppData\\Local\\Programs\\Venvs\\main\\lib\\site-packages\\pandas\\core\\arraylike.py:194\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__sub__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__sub__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m--> 194\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arith_method(other, operator\u001b[39m.\u001b[39;49msub)\n",
      "File \u001b[1;32mc:\\Users\\elaty\\AppData\\Local\\Programs\\Venvs\\main\\lib\\site-packages\\pandas\\core\\frame.py:7461\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   7457\u001b[0m other \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mmaybe_prepare_scalar_for_op(other, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[axis],))\n\u001b[0;32m   7459\u001b[0m \u001b[39mself\u001b[39m, other \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39malign_method_FRAME(\u001b[39mself\u001b[39m, other, axis, flex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, level\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 7461\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch_frame_op(other, op, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   7462\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[1;32mc:\\Users\\elaty\\AppData\\Local\\Programs\\Venvs\\main\\lib\\site-packages\\pandas\\core\\frame.py:7500\u001b[0m, in \u001b[0;36mDataFrame._dispatch_frame_op\u001b[1;34m(self, right, func, axis)\u001b[0m\n\u001b[0;32m   7494\u001b[0m     \u001b[39m# TODO: The previous assertion `assert right._indexed_same(self)`\u001b[39;00m\n\u001b[0;32m   7495\u001b[0m     \u001b[39m#  fails in cases with empty columns reached via\u001b[39;00m\n\u001b[0;32m   7496\u001b[0m     \u001b[39m#  _frame_arith_method_with_reindex\u001b[39;00m\n\u001b[0;32m   7497\u001b[0m \n\u001b[0;32m   7498\u001b[0m     \u001b[39m# TODO operate_blockwise expects a manager of the same type\u001b[39;00m\n\u001b[0;32m   7499\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 7500\u001b[0m         bm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49moperate_blockwise(\n\u001b[0;32m   7501\u001b[0m             \u001b[39m# error: Argument 1 to \"operate_blockwise\" of \"ArrayManager\" has\u001b[39;49;00m\n\u001b[0;32m   7502\u001b[0m             \u001b[39m# incompatible type \"Union[ArrayManager, BlockManager]\"; expected\u001b[39;49;00m\n\u001b[0;32m   7503\u001b[0m             \u001b[39m# \"ArrayManager\"\u001b[39;49;00m\n\u001b[0;32m   7504\u001b[0m             \u001b[39m# error: Argument 1 to \"operate_blockwise\" of \"BlockManager\" has\u001b[39;49;00m\n\u001b[0;32m   7505\u001b[0m             \u001b[39m# incompatible type \"Union[ArrayManager, BlockManager]\"; expected\u001b[39;49;00m\n\u001b[0;32m   7506\u001b[0m             \u001b[39m# \"BlockManager\"\u001b[39;49;00m\n\u001b[0;32m   7507\u001b[0m             right\u001b[39m.\u001b[39;49m_mgr,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   7508\u001b[0m             array_op,\n\u001b[0;32m   7509\u001b[0m         )\n\u001b[0;32m   7510\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(bm)\n\u001b[0;32m   7512\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(right, Series) \u001b[39mand\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   7513\u001b[0m     \u001b[39m# axis=1 means we want to operate row-by-row\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\elaty\\AppData\\Local\\Programs\\Venvs\\main\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1545\u001b[0m, in \u001b[0;36mBlockManager.operate_blockwise\u001b[1;34m(self, other, array_op)\u001b[0m\n\u001b[0;32m   1541\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moperate_blockwise\u001b[39m(\u001b[39mself\u001b[39m, other: BlockManager, array_op) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BlockManager:\n\u001b[0;32m   1542\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1543\u001b[0m \u001b[39m    Apply array_op blockwise with another (aligned) BlockManager.\u001b[39;00m\n\u001b[0;32m   1544\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1545\u001b[0m     \u001b[39mreturn\u001b[39;00m operate_blockwise(\u001b[39mself\u001b[39;49m, other, array_op)\n",
      "File \u001b[1;32mc:\\Users\\elaty\\AppData\\Local\\Programs\\Venvs\\main\\lib\\site-packages\\pandas\\core\\internals\\ops.py:63\u001b[0m, in \u001b[0;36moperate_blockwise\u001b[1;34m(left, right, array_op)\u001b[0m\n\u001b[0;32m     61\u001b[0m res_blks: \u001b[39mlist\u001b[39m[Block] \u001b[39m=\u001b[39m []\n\u001b[0;32m     62\u001b[0m \u001b[39mfor\u001b[39;00m lvals, rvals, locs, left_ea, right_ea, rblk \u001b[39min\u001b[39;00m _iter_block_pairs(left, right):\n\u001b[1;32m---> 63\u001b[0m     res_values \u001b[39m=\u001b[39m array_op(lvals, rvals)\n\u001b[0;32m     64\u001b[0m     \u001b[39mif\u001b[39;00m left_ea \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m right_ea \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(res_values, \u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     65\u001b[0m         res_values \u001b[39m=\u001b[39m res_values\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\elaty\\AppData\\Local\\Programs\\Venvs\\main\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:225\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    221\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[0;32m    223\u001b[0m     \u001b[39m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     \u001b[39m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 225\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(left, right, op)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[39mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mc:\\Users\\elaty\\AppData\\Local\\Programs\\Venvs\\main\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:171\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_cmp \u001b[39mand\u001b[39;00m (is_object_dtype(left\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(right)):\n\u001b[0;32m    167\u001b[0m         \u001b[39m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[0;32m    168\u001b[0m         \u001b[39m#  on the non-missing values)\u001b[39;00m\n\u001b[0;32m    169\u001b[0m         \u001b[39m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    170\u001b[0m         \u001b[39m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m         result \u001b[39m=\u001b[39m _masked_arith_op(left, right, op)\n\u001b[0;32m    172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m         \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\elaty\\AppData\\Local\\Programs\\Venvs\\main\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:109\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[1;34m(x, y, op)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[39m# See GH#5284, GH#5035, GH#19448 for historical reference\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m--> 109\u001b[0m         result[mask] \u001b[39m=\u001b[39m op(xrav[mask], yrav[mask])\n\u001b[0;32m    111\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(y):\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "# for each row in the dataframe, get the AA sequence of Interactor A and Interactor B\n",
    "print(\"For each row in the dataframe, get the AA sequence of Interactor A and Interactor B...\")\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "\n",
    "    # get the RefSeq IDs of Interactor A and Interactor B\n",
    "    interactor_a = df.loc[i, \"Interactor A\"]\n",
    "    interactor_b = df.loc[i, \"Interactor B\"]\n",
    "\n",
    "    # get the AA sequences of Interactor A and Interactor B if they exist\n",
    "    if interactor_a in sequences and interactor_b in sequences:\n",
    "        seq_a = sequences[interactor_a]\n",
    "        seq_b = sequences[interactor_b]\n",
    "\n",
    "        # add the row to the new dataframe\n",
    "        df_new = pd.concat([df_new, pd.DataFrame([[seq_a, seq_b]], columns=[\"Interactor A\", \"Interactor B\"])])\n",
    "print(\"Done!\")\n",
    "\n",
    "# print the shape of the new dataframe\n",
    "print(f\"Shape of the new dataframe: {df_new.shape}\")\n",
    "\n",
    "# save the dataframe as a csv file\n",
    "print(\"Saving the dataframe as a csv file...\")\n",
    "df_new.to_csv(\"../data/data_conc_100k_aa.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
