{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow_gnn as tfgnn\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from model import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_methods = [\"same_degree_distribution\", \"most_close\", \"most_distant\"]\n",
    "\n",
    "k = 5\n",
    "\n",
    "# define the search space\n",
    "space = {\n",
    "    'learning_rate': hp.loguniform('learning_rate', -6, -2),\n",
    "    'optimizer': hp.choice('optimizer', ['sgd', 'adam', 'nadam']),\n",
    "    'activation': hp.choice('activation', ['relu', 'sigmoid', 'tanh', 'leaky_relu'])\n",
    "}\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make and early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params, negative_method):\n",
    "    # unpack the parameters\n",
    "    learning_rate = params['learning_rate']\n",
    "    optimizer_type = params['optimizer']\n",
    "    activation = params['activation']\n",
    "\n",
    "\n",
    "\n",
    "    # Create a graph of protein interactions for each method\n",
    "    graphToTensor = GraphToTensor(negative_interaction_method=negative_method)\n",
    "    graph_tensor = graphToTensor.graph_tensor\n",
    "\n",
    "    dataset = create_dataset(graph_tensor, edge_batch_merge)\n",
    "\n",
    "    graph_spec = dataset.element_spec[0]\n",
    "    input_graph = tf.keras.layers.Input(type_spec=graph_spec)\n",
    "\n",
    "    # Generate k-folds for each method\n",
    "    kfolds = graphToTensor.generate_graph_tensors_for_k_folds(k_folds=k)\n",
    "\n",
    "    # for storing y and yhat across all folds\n",
    "    y_folds = []\n",
    "    yhat_folds = []\n",
    "\n",
    "    for i, (train_graph, test_graph) in enumerate(kfolds):\n",
    "\n",
    "        # Create datasets for this fold\n",
    "        train_dataset = create_dataset(train_graph, edge_batch_merge)\n",
    "        test_dataset = create_dataset(test_graph, edge_batch_merge)\n",
    "\n",
    "        model = create_model(input_graph, graph_updates=3, activation=activation)\n",
    "\n",
    "        # choose the optimizer\n",
    "        if optimizer_type == 'sgd':\n",
    "            optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "        elif optimizer_type == 'adam':\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        elif optimizer_type == 'nadam':\n",
    "            optimizer = tf.keras.optimizers.Nadam(learning_rate=learning_rate)\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(\n",
    "            optimizer,\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['Accuracy']\n",
    "        )\n",
    "            \n",
    "        # Fit the model for this fold\n",
    "        model.fit(\n",
    "            train_dataset.repeat(),\n",
    "            epochs=1000,\n",
    "            steps_per_epoch=10,\n",
    "            validation_data=test_dataset.repeat(),\n",
    "            validation_steps=10,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # store y and yhat for this fold\n",
    "        yhat = model.predict(test_dataset, verbose=0)\n",
    "        y = test_dataset.map(lambda graph, labels: labels).unbatch()\n",
    "        y = np.array(list(y.as_numpy_iterator()))\n",
    "        yhat = np.array(list(yhat))\n",
    "\n",
    "        y_folds.append(y)\n",
    "        yhat_folds.append(yhat)\n",
    "\n",
    "        # Delete the model to free up memory\n",
    "        del model\n",
    "\n",
    "    # get the predictions for all folds\n",
    "    y = np.concatenate(y_folds)\n",
    "    yhat = np.concatenate(yhat_folds)\n",
    "\n",
    "    accuracy = accuracy_score(y, yhat.round())\n",
    "\n",
    "    # use accuracy as the objective to maximize\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing for most_distant...\n",
      " 10%|â–ˆ         | 1/10 [09:48<1:28:14, 588.30s/trial, best loss: -0.9541086865700421]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39m# run the hyperparameter optimization\u001b[39;00m\n\u001b[0;32m      9\u001b[0m trials \u001b[39m=\u001b[39m Trials()\n\u001b[1;32m---> 10\u001b[0m best \u001b[39m=\u001b[39m fmin(\n\u001b[0;32m     11\u001b[0m     fn\u001b[39m=\u001b[39;49mobjective_partial,\n\u001b[0;32m     12\u001b[0m     space\u001b[39m=\u001b[39;49mspace,\n\u001b[0;32m     13\u001b[0m     algo\u001b[39m=\u001b[39;49mtpe\u001b[39m.\u001b[39;49msuggest,\n\u001b[0;32m     14\u001b[0m     max_evals\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m     15\u001b[0m     trials\u001b[39m=\u001b[39;49mtrials\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[39m# store the best parameters for this method\u001b[39;00m\n\u001b[0;32m     19\u001b[0m best_params_per_method[method] \u001b[39m=\u001b[39m best\n",
      "File \u001b[1;32mc:\\Users\\AHMED MRABET\\anaconda3\\envs\\tf\\lib\\site-packages\\hyperopt\\fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    537\u001b[0m     fn \u001b[39m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[0;32m    539\u001b[0m \u001b[39mif\u001b[39;00m allow_trials_fmin \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(trials, \u001b[39m\"\u001b[39m\u001b[39mfmin\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     \u001b[39mreturn\u001b[39;00m trials\u001b[39m.\u001b[39;49mfmin(\n\u001b[0;32m    541\u001b[0m         fn,\n\u001b[0;32m    542\u001b[0m         space,\n\u001b[0;32m    543\u001b[0m         algo\u001b[39m=\u001b[39;49malgo,\n\u001b[0;32m    544\u001b[0m         max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[0;32m    545\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    546\u001b[0m         loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[0;32m    547\u001b[0m         max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[0;32m    548\u001b[0m         rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[0;32m    549\u001b[0m         pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[0;32m    550\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    551\u001b[0m         catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[0;32m    552\u001b[0m         return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[0;32m    553\u001b[0m         show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[0;32m    554\u001b[0m         early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[0;32m    555\u001b[0m         trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[0;32m    556\u001b[0m     )\n\u001b[0;32m    558\u001b[0m \u001b[39mif\u001b[39;00m trials \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[1;32mc:\\Users\\AHMED MRABET\\anaconda3\\envs\\tf\\lib\\site-packages\\hyperopt\\base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[39m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[39m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[39m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfmin\u001b[39;00m \u001b[39mimport\u001b[39;00m fmin\n\u001b[1;32m--> 671\u001b[0m \u001b[39mreturn\u001b[39;00m fmin(\n\u001b[0;32m    672\u001b[0m     fn,\n\u001b[0;32m    673\u001b[0m     space,\n\u001b[0;32m    674\u001b[0m     algo\u001b[39m=\u001b[39;49malgo,\n\u001b[0;32m    675\u001b[0m     max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[0;32m    676\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    677\u001b[0m     loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[0;32m    678\u001b[0m     trials\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    679\u001b[0m     rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[0;32m    680\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    681\u001b[0m     max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[0;32m    682\u001b[0m     allow_trials_fmin\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# -- prevent recursion\u001b[39;49;00m\n\u001b[0;32m    683\u001b[0m     pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[0;32m    684\u001b[0m     catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[0;32m    685\u001b[0m     return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[0;32m    686\u001b[0m     show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[0;32m    687\u001b[0m     early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[0;32m    688\u001b[0m     trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[0;32m    689\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\AHMED MRABET\\anaconda3\\envs\\tf\\lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m rval\u001b[39m.\u001b[39;49mexhaust()\n\u001b[0;32m    588\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\AHMED MRABET\\anaconda3\\envs\\tf\\lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals \u001b[39m-\u001b[39;49m n_done, block_until_done\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masynchronous)\n\u001b[0;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\AHMED MRABET\\anaconda3\\envs\\tf\\lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[39m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserial_evaluate()\n\u001b[0;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials_save_file \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\AHMED MRABET\\anaconda3\\envs\\tf\\lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mCtrl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials, current_trial\u001b[39m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain\u001b[39m.\u001b[39;49mevaluate(spec, ctrl)\n\u001b[0;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mjob exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[1;32mc:\\Users\\AHMED MRABET\\anaconda3\\envs\\tf\\lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[39m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[39m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[39m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[39m=\u001b[39m pyll\u001b[39m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[39m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(pyll_rval)\n\u001b[0;32m    894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rval, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(rval), \u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(params, negative_method)\u001b[0m\n\u001b[0;32m      5\u001b[0m activation \u001b[39m=\u001b[39m params[\u001b[39m'\u001b[39m\u001b[39mactivation\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[39m# Create a graph of protein interactions for each method\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m graphToTensor \u001b[39m=\u001b[39m GraphToTensor(negative_interaction_method\u001b[39m=\u001b[39;49mnegative_method)\n\u001b[0;32m     11\u001b[0m graph_tensor \u001b[39m=\u001b[39m graphToTensor\u001b[39m.\u001b[39mgraph_tensor\n\u001b[0;32m     13\u001b[0m dataset \u001b[39m=\u001b[39m create_dataset(graph_tensor, edge_batch_merge)\n",
      "File \u001b[1;32mc:\\Users\\AHMED MRABET\\Documents\\ENSIAS-Workspace\\PFA\\Protein-on-Protein-Interactions-Prediction\\src\\utils\\graph_utils.py:16\u001b[0m, in \u001b[0;36mGraphToTensor.__init__\u001b[1;34m(self, negative_interaction_method)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_data()\n\u001b[0;32m     15\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_features()\n\u001b[1;32m---> 16\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madjacency_matrix, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_graph(negative_interaction_method)\n\u001b[0;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_mapping \u001b[39m=\u001b[39m {node: i \u001b[39mfor\u001b[39;00m i, node \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mnodes)}\n\u001b[0;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph_tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_graph_tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph)\n",
      "File \u001b[1;32mc:\\Users\\AHMED MRABET\\Documents\\ENSIAS-Workspace\\PFA\\Protein-on-Protein-Interactions-Prediction\\src\\utils\\graph_utils.py:63\u001b[0m, in \u001b[0;36mGraphToTensor.generate_graph\u001b[1;34m(self, negative_interaction_method)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_nodes_to_graph(G)\n\u001b[0;32m     62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_positive_interactions(G)\n\u001b[1;32m---> 63\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_negative_interactions(G, negative_interaction_method)\n\u001b[0;32m     64\u001b[0m adjacency_matrix \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39madjacency_matrix(G)\u001b[39m.\u001b[39mtoarray()\n\u001b[0;32m     65\u001b[0m \u001b[39mreturn\u001b[39;00m G, adjacency_matrix, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_node_features(G)\n",
      "File \u001b[1;32mc:\\Users\\AHMED MRABET\\Documents\\ENSIAS-Workspace\\PFA\\Protein-on-Protein-Interactions-Prediction\\src\\utils\\graph_utils.py:55\u001b[0m, in \u001b[0;36mGraphToTensor.add_negative_interactions\u001b[1;34m(self, G, negative_interaction_method)\u001b[0m\n\u001b[0;32m     53\u001b[0m     negative_interactions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmost_close(G)\n\u001b[0;32m     54\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# most_distant\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     negative_interactions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmost_distant(G)\n\u001b[0;32m     56\u001b[0m \u001b[39mfor\u001b[39;00m pair \u001b[39min\u001b[39;00m negative_interactions:\n\u001b[0;32m     57\u001b[0m     G\u001b[39m.\u001b[39madd_edge(pair[\u001b[39m0\u001b[39m], pair[\u001b[39m1\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\AHMED MRABET\\Documents\\ENSIAS-Workspace\\PFA\\Protein-on-Protein-Interactions-Prediction\\src\\utils\\graph_utils.py:95\u001b[0m, in \u001b[0;36mmost_distant\u001b[1;34m(self, positive_graph)\u001b[0m\n\u001b[0;32m     90\u001b[0m     negative_interactions \u001b[39m=\u001b[39m non_edges_sorted[:\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf)]\n\u001b[0;32m     91\u001b[0m     \u001b[39mreturn\u001b[39;00m negative_interactions\n\u001b[1;32m---> 95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_graph_tensor\u001b[39m(\u001b[39mself\u001b[39m, graph):\n\u001b[0;32m     96\u001b[0m     edge_sources \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_mapping[e[\u001b[39m0\u001b[39m]] \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m graph\u001b[39m.\u001b[39medges], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)\n\u001b[0;32m     97\u001b[0m     edge_targets \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_mapping[e[\u001b[39m1\u001b[39m]] \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m graph\u001b[39m.\u001b[39medges], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)\n",
      "File \u001b[1;32mc:\\Users\\AHMED MRABET\\Documents\\ENSIAS-Workspace\\PFA\\Protein-on-Protein-Interactions-Prediction\\src\\utils\\graph_utils.py:95\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     90\u001b[0m     negative_interactions \u001b[39m=\u001b[39m non_edges_sorted[:\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf)]\n\u001b[0;32m     91\u001b[0m     \u001b[39mreturn\u001b[39;00m negative_interactions\n\u001b[1;32m---> 95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_graph_tensor\u001b[39m(\u001b[39mself\u001b[39m, graph):\n\u001b[0;32m     96\u001b[0m     edge_sources \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_mapping[e[\u001b[39m0\u001b[39m]] \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m graph\u001b[39m.\u001b[39medges], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)\n\u001b[0;32m     97\u001b[0m     edge_targets \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_mapping[e[\u001b[39m1\u001b[39m]] \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m graph\u001b[39m.\u001b[39medges], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\AHMED MRABET\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\linalg\\linalg.py:2526\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2524\u001b[0m     sqnorm \u001b[39m=\u001b[39m x_real\u001b[39m.\u001b[39mdot(x_real) \u001b[39m+\u001b[39m x_imag\u001b[39m.\u001b[39mdot(x_imag)\n\u001b[0;32m   2525\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2526\u001b[0m     sqnorm \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mdot(x)\n\u001b[0;32m   2527\u001b[0m ret \u001b[39m=\u001b[39m sqrt(sqnorm)\n\u001b[0;32m   2528\u001b[0m \u001b[39mif\u001b[39;00m keepdims:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "best_params_per_method = {}\n",
    "\n",
    "for method in negative_methods:\n",
    "    print(f'Optimizing for {method}...')\n",
    "    # create a partial function with the negative method as a parameter\n",
    "    objective_partial = partial(objective, negative_method=method)\n",
    "\n",
    "    # run the hyperparameter optimization\n",
    "    trials = Trials()\n",
    "    best = fmin(\n",
    "        fn=objective_partial,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=10,\n",
    "        trials=trials\n",
    "    )\n",
    "\n",
    "    # store the best parameters for this method\n",
    "    best_params_per_method[method] = best\n",
    "\n",
    "    # store the results\n",
    "    results[method] = trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for random_pairs:\n",
      "{'activation': 1, 'learning_rate': 0.08713927895359477, 'optimizer': 2}\n",
      "Best parameters for same_degree_distribution:\n",
      "{'activation': 0, 'learning_rate': 0.058642938686967135, 'optimizer': 1}\n",
      "Best parameters for most_close:\n",
      "{'activation': 3, 'learning_rate': 0.05637113155272348, 'optimizer': 1}\n",
      "Best parameters for most_distant:\n",
      "{'activation': 0, 'learning_rate': 0.054942454073653696, 'optimizer': 2}\n"
     ]
    }
   ],
   "source": [
    "# print the best parameters for each method\n",
    "for method, best_params in best_params_per_method.items():\n",
    "    print(f'Best parameters for {method}: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Prepare data for DataFrame\n",
    "# data = []\n",
    "# for method, metrics in results.items():\n",
    "#     for metric, score in metrics.items():\n",
    "#         data.append([method, metric, score])\n",
    "\n",
    "# # Create DataFrame\n",
    "# results_df = pd.DataFrame(data, columns=['Methods', 'Metrics', 'Score'])\n",
    "\n",
    "# # Create the plot\n",
    "# plt.figure(figsize=(12,8))\n",
    "# bar_plot = sns.barplot(x='Methods', y='Score', hue='Metrics', data=results_df, palette='muted', saturation=0.9)\n",
    "\n",
    "# # Add labels to the top of the bars\n",
    "# for p in bar_plot.patches:\n",
    "#     bar_plot.annotate(format(p.get_height(), '.2f'), \n",
    "#                       (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "#                       ha = 'center', \n",
    "#                       va = 'center', \n",
    "#                       xytext = (0, 10), \n",
    "#                       textcoords = 'offset points')\n",
    "\n",
    "# # Move the legend outside the plot\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
