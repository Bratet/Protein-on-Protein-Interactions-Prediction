{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence 1</th>\n",
       "      <th>Sequence 2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MVAHNQVAADNAVSTAAEPRRRPEPSSSSSSSPAAPARPRPCPAVP...</td>\n",
       "      <td>MRGARGAWDFLCVLLLLLRVQTGSSQPSVSPGEPSPPSIHPGKSDL...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MFRTKRSALVRRLWRSRAPGGEDEEEGAGGGGGGGELRGEGATDSR...</td>\n",
       "      <td>MFRTKRSALVRRLWRSRAPGGEDEEEGAGGGGGGGELRGEGATDSR...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MPSRTGPKMEGSGGRVRLKAHYGGDIFITSVDAATTFEELCEEVRD...</td>\n",
       "      <td>MKSNQERSNECLPPKKREIPATSRSSEEKAPTLPSDNHRVEGTAWL...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MGSNKSKPKDASQRRRSLEPAENVHGAGGGAFPASQTPSKPASADG...</td>\n",
       "      <td>MVKISFQPAVAGIKGDKADKASASAPAPASATEILLTPAREEQPPQ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MQSKVLLAVALWLCVETRAASVGLPSVSLDLPRLSIQKDILTIKAN...</td>\n",
       "      <td>MATQADLMELDMAMEPDRKAAVSHWQQQSYLDSGIHSGATTTAPSL...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Sequence 1  \\\n",
       "0  MVAHNQVAADNAVSTAAEPRRRPEPSSSSSSSPAAPARPRPCPAVP...   \n",
       "1  MFRTKRSALVRRLWRSRAPGGEDEEEGAGGGGGGGELRGEGATDSR...   \n",
       "2  MPSRTGPKMEGSGGRVRLKAHYGGDIFITSVDAATTFEELCEEVRD...   \n",
       "3  MGSNKSKPKDASQRRRSLEPAENVHGAGGGAFPASQTPSKPASADG...   \n",
       "4  MQSKVLLAVALWLCVETRAASVGLPSVSLDLPRLSIQKDILTIKAN...   \n",
       "\n",
       "                                          Sequence 2  label  \n",
       "0  MRGARGAWDFLCVLLLLLRVQTGSSQPSVSPGEPSPPSIHPGKSDL...      1  \n",
       "1  MFRTKRSALVRRLWRSRAPGGEDEEEGAGGGGGGGELRGEGATDSR...      1  \n",
       "2  MKSNQERSNECLPPKKREIPATSRSSEEKAPTLPSDNHRVEGTAWL...      0  \n",
       "3  MVKISFQPAVAGIKGDKADKASASAPAPASATEILLTPAREEQPPQ...      0  \n",
       "4  MATQADLMELDMAMEPDRKAAVSHWQQQSYLDSGIHSGATTTAPSL...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_df = pd.read_csv('generateDB/data/sequence_data.csv')\n",
    "positive_df['label'] = 1\n",
    "negative_df = pd.read_csv('generateDB/data/negative_data.csv')\n",
    "negative_df['label'] = 0\n",
    "\n",
    "# combine the dataframes\n",
    "df = pd.concat([positive_df, negative_df], ignore_index=True)\n",
    "\n",
    "# shuffle the data\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature_extractor import extract_features\n",
    "\n",
    "# extract features from the sequences 1\n",
    "features_1 = df['Sequence 1'].apply(extract_features)\n",
    "# convert the features to a numpy array\n",
    "features_1 = np.array(features_1.tolist())\n",
    "\n",
    "# extract features from the sequences 2\n",
    "features_2 = df['Sequence 2'].apply(extract_features)\n",
    "# convert the features to a numpy array\n",
    "features_2 = np.array(features_2.tolist())\n",
    "\n",
    "# extract the labels\n",
    "labels = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65393/65393 [04:05<00:00, 265.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecular_weight_1</th>\n",
       "      <th>isoelectric_point_1</th>\n",
       "      <th>alanine_1</th>\n",
       "      <th>arginine_1</th>\n",
       "      <th>asparagine_1</th>\n",
       "      <th>aspartic_acid_1</th>\n",
       "      <th>cysteine_1</th>\n",
       "      <th>glutamic_acid_1</th>\n",
       "      <th>glutamine_1</th>\n",
       "      <th>glycine_1</th>\n",
       "      <th>...</th>\n",
       "      <th>lysine_2</th>\n",
       "      <th>methionine_2</th>\n",
       "      <th>phenylalanine_2</th>\n",
       "      <th>proline_2</th>\n",
       "      <th>serine_2</th>\n",
       "      <th>threonine_2</th>\n",
       "      <th>tryptophan_2</th>\n",
       "      <th>tyrosine_2</th>\n",
       "      <th>valine_2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23550.6179</td>\n",
       "      <td>10.979691</td>\n",
       "      <td>0.123223</td>\n",
       "      <td>0.023697</td>\n",
       "      <td>0.037915</td>\n",
       "      <td>0.042654</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.047393</td>\n",
       "      <td>0.037915</td>\n",
       "      <td>0.023697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055328</td>\n",
       "      <td>0.051230</td>\n",
       "      <td>0.025615</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>0.080943</td>\n",
       "      <td>0.060451</td>\n",
       "      <td>0.079918</td>\n",
       "      <td>0.014344</td>\n",
       "      <td>0.043033</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46425.2922</td>\n",
       "      <td>8.630592</td>\n",
       "      <td>0.072770</td>\n",
       "      <td>0.044601</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.032864</td>\n",
       "      <td>0.115023</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.023474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023474</td>\n",
       "      <td>0.077465</td>\n",
       "      <td>0.039906</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>0.077465</td>\n",
       "      <td>0.035211</td>\n",
       "      <td>0.051643</td>\n",
       "      <td>0.018779</td>\n",
       "      <td>0.030516</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67659.2067</td>\n",
       "      <td>5.485838</td>\n",
       "      <td>0.045608</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.084459</td>\n",
       "      <td>0.072635</td>\n",
       "      <td>0.048986</td>\n",
       "      <td>0.070946</td>\n",
       "      <td>0.030405</td>\n",
       "      <td>0.060811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026994</td>\n",
       "      <td>0.106748</td>\n",
       "      <td>0.089571</td>\n",
       "      <td>0.035583</td>\n",
       "      <td>0.109202</td>\n",
       "      <td>0.058896</td>\n",
       "      <td>0.063804</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>0.023313</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59834.0535</td>\n",
       "      <td>7.103817</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>0.016791</td>\n",
       "      <td>0.039179</td>\n",
       "      <td>0.078358</td>\n",
       "      <td>0.039179</td>\n",
       "      <td>0.080224</td>\n",
       "      <td>0.016791</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041199</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>0.037453</td>\n",
       "      <td>0.074906</td>\n",
       "      <td>0.052434</td>\n",
       "      <td>0.048689</td>\n",
       "      <td>0.086142</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.048689</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151525.0639</td>\n",
       "      <td>5.600141</td>\n",
       "      <td>0.050147</td>\n",
       "      <td>0.024336</td>\n",
       "      <td>0.050885</td>\n",
       "      <td>0.075959</td>\n",
       "      <td>0.030236</td>\n",
       "      <td>0.062684</td>\n",
       "      <td>0.019174</td>\n",
       "      <td>0.058997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039693</td>\n",
       "      <td>0.044814</td>\n",
       "      <td>0.062740</td>\n",
       "      <td>0.049936</td>\n",
       "      <td>0.053777</td>\n",
       "      <td>0.061460</td>\n",
       "      <td>0.069142</td>\n",
       "      <td>0.008963</td>\n",
       "      <td>0.021767</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   molecular_weight_1  isoelectric_point_1  alanine_1  arginine_1  \\\n",
       "0          23550.6179            10.979691   0.123223    0.023697   \n",
       "1          46425.2922             8.630592   0.072770    0.044601   \n",
       "2          67659.2067             5.485838   0.045608    0.027027   \n",
       "3          59834.0535             7.103817   0.082090    0.016791   \n",
       "4         151525.0639             5.600141   0.050147    0.024336   \n",
       "\n",
       "   asparagine_1  aspartic_acid_1  cysteine_1  glutamic_acid_1  glutamine_1  \\\n",
       "0      0.037915         0.042654    0.056872         0.047393     0.037915   \n",
       "1      0.042254         0.056338    0.032864         0.115023     0.028169   \n",
       "2      0.084459         0.072635    0.048986         0.070946     0.030405   \n",
       "3      0.039179         0.078358    0.039179         0.080224     0.016791   \n",
       "4      0.050885         0.075959    0.030236         0.062684     0.019174   \n",
       "\n",
       "   glycine_1  ...  lysine_2  methionine_2  phenylalanine_2  proline_2  \\\n",
       "0   0.023697  ...  0.055328      0.051230         0.025615   0.040984   \n",
       "1   0.023474  ...  0.023474      0.077465         0.039906   0.070423   \n",
       "2   0.060811  ...  0.026994      0.106748         0.089571   0.035583   \n",
       "3   0.029851  ...  0.041199      0.044944         0.037453   0.074906   \n",
       "4   0.058997  ...  0.039693      0.044814         0.062740   0.049936   \n",
       "\n",
       "   serine_2  threonine_2  tryptophan_2  tyrosine_2  valine_2  label  \n",
       "0  0.080943     0.060451      0.079918    0.014344  0.043033    1.0  \n",
       "1  0.077465     0.035211      0.051643    0.018779  0.030516    1.0  \n",
       "2  0.109202     0.058896      0.063804    0.003681  0.023313    0.0  \n",
       "3  0.052434     0.048689      0.086142    0.003745  0.048689    0.0  \n",
       "4  0.053777     0.061460      0.069142    0.008963  0.021767    1.0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df = pd.DataFrame(columns=['molecular_weight_1', 'isoelectric_point_1', 'alanine_1', 'arginine_1', 'asparagine_1', 'aspartic_acid_1', 'cysteine_1', 'glutamic_acid_1', 'glutamine_1', 'glycine_1', 'histidine_1', 'isoleucine_1', 'leucine_1', 'lysine_1', 'methionine_1', 'phenylalanine_1', 'proline_1', 'serine_1', 'threonine_1', 'tryptophan_1', 'tyrosine_1', 'valine_1', 'molecular_weight_2', 'isoelectric_point_2', 'alanine_2', 'arginine_2', 'asparagine_2', 'aspartic_acid_2', 'cysteine_2', 'glutamic_acid_2', 'glutamine_2', 'glycine_2', 'histidine_2', 'isoleucine_2', 'leucine_2', 'lysine_2', 'methionine_2', 'phenylalanine_2', 'proline_2', 'serine_2', 'threonine_2', 'tryptophan_2', 'tyrosine_2', 'valine_2', 'label'])\n",
    "\n",
    "for i in tqdm(range(len(features_1))):\n",
    "    feature_df.loc[i] = np.concatenate((features_1[i], features_2[i], [labels[i]]))\n",
    "    \n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.to_csv('generateDB/data/feature_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_df.drop('label', axis=1), feature_df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GNN to train the model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "hidden_layer_1 = Dense(64, activation='relu')(input_layer)\n",
    "hidden_layer_2 = Dense(32, activation='relu')(hidden_layer_1)\n",
    "output_layer = Dense(1, activation='sigmoid')(hidden_layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AHMED MRABET\\miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "409/409 [==============================] - 3s 3ms/step - loss: 0.5955 - accuracy: 0.6963 - val_loss: 0.4747 - val_accuracy: 0.8023\n",
      "Epoch 2/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.4066 - accuracy: 0.8495 - val_loss: 0.3571 - val_accuracy: 0.8753\n",
      "Epoch 3/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.3210 - accuracy: 0.8857 - val_loss: 0.3016 - val_accuracy: 0.8928\n",
      "Epoch 4/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.2809 - accuracy: 0.8981 - val_loss: 0.2760 - val_accuracy: 0.9008\n",
      "Epoch 5/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.2597 - accuracy: 0.9066 - val_loss: 0.2612 - val_accuracy: 0.9061\n",
      "Epoch 6/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.2456 - accuracy: 0.9119 - val_loss: 0.2504 - val_accuracy: 0.9099\n",
      "Epoch 7/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.2347 - accuracy: 0.9156 - val_loss: 0.2417 - val_accuracy: 0.9138\n",
      "Epoch 8/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.2258 - accuracy: 0.9188 - val_loss: 0.2342 - val_accuracy: 0.9164\n",
      "Epoch 9/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.2183 - accuracy: 0.9216 - val_loss: 0.2277 - val_accuracy: 0.9189\n",
      "Epoch 10/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.2116 - accuracy: 0.9244 - val_loss: 0.2220 - val_accuracy: 0.9199\n",
      "Epoch 11/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.2057 - accuracy: 0.9262 - val_loss: 0.2172 - val_accuracy: 0.9221\n",
      "Epoch 12/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.2005 - accuracy: 0.9281 - val_loss: 0.2126 - val_accuracy: 0.9235\n",
      "Epoch 13/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1957 - accuracy: 0.9298 - val_loss: 0.2085 - val_accuracy: 0.9237\n",
      "Epoch 14/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1914 - accuracy: 0.9310 - val_loss: 0.2045 - val_accuracy: 0.9258\n",
      "Epoch 15/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1876 - accuracy: 0.9329 - val_loss: 0.2011 - val_accuracy: 0.9274\n",
      "Epoch 16/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1840 - accuracy: 0.9341 - val_loss: 0.1981 - val_accuracy: 0.9282\n",
      "Epoch 17/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1807 - accuracy: 0.9349 - val_loss: 0.1951 - val_accuracy: 0.9294\n",
      "Epoch 18/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1776 - accuracy: 0.9361 - val_loss: 0.1924 - val_accuracy: 0.9313\n",
      "Epoch 19/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1748 - accuracy: 0.9373 - val_loss: 0.1904 - val_accuracy: 0.9320\n",
      "Epoch 20/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1723 - accuracy: 0.9385 - val_loss: 0.1878 - val_accuracy: 0.9334\n",
      "Epoch 21/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1698 - accuracy: 0.9392 - val_loss: 0.1862 - val_accuracy: 0.9344\n",
      "Epoch 22/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1676 - accuracy: 0.9400 - val_loss: 0.1840 - val_accuracy: 0.9344\n",
      "Epoch 23/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1655 - accuracy: 0.9407 - val_loss: 0.1824 - val_accuracy: 0.9356\n",
      "Epoch 24/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1636 - accuracy: 0.9415 - val_loss: 0.1803 - val_accuracy: 0.9355\n",
      "Epoch 25/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1617 - accuracy: 0.9426 - val_loss: 0.1788 - val_accuracy: 0.9366\n",
      "Epoch 26/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1600 - accuracy: 0.9432 - val_loss: 0.1773 - val_accuracy: 0.9372\n",
      "Epoch 27/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1583 - accuracy: 0.9438 - val_loss: 0.1757 - val_accuracy: 0.9375\n",
      "Epoch 28/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1567 - accuracy: 0.9443 - val_loss: 0.1745 - val_accuracy: 0.9381\n",
      "Epoch 29/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1551 - accuracy: 0.9449 - val_loss: 0.1734 - val_accuracy: 0.9379\n",
      "Epoch 30/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1537 - accuracy: 0.9454 - val_loss: 0.1718 - val_accuracy: 0.9392\n",
      "Epoch 31/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1523 - accuracy: 0.9461 - val_loss: 0.1705 - val_accuracy: 0.9393\n",
      "Epoch 32/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1509 - accuracy: 0.9471 - val_loss: 0.1693 - val_accuracy: 0.9404\n",
      "Epoch 33/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1495 - accuracy: 0.9472 - val_loss: 0.1682 - val_accuracy: 0.9408\n",
      "Epoch 34/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1483 - accuracy: 0.9480 - val_loss: 0.1669 - val_accuracy: 0.9414\n",
      "Epoch 35/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1471 - accuracy: 0.9484 - val_loss: 0.1659 - val_accuracy: 0.9421\n",
      "Epoch 36/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1458 - accuracy: 0.9486 - val_loss: 0.1646 - val_accuracy: 0.9430\n",
      "Epoch 37/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1446 - accuracy: 0.9493 - val_loss: 0.1637 - val_accuracy: 0.9437\n",
      "Epoch 38/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1434 - accuracy: 0.9496 - val_loss: 0.1626 - val_accuracy: 0.9443\n",
      "Epoch 39/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1423 - accuracy: 0.9501 - val_loss: 0.1617 - val_accuracy: 0.9443\n",
      "Epoch 40/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1411 - accuracy: 0.9509 - val_loss: 0.1608 - val_accuracy: 0.9443\n",
      "Epoch 41/100\n",
      "409/409 [==============================] - 1s 3ms/step - loss: 0.1401 - accuracy: 0.9514 - val_loss: 0.1602 - val_accuracy: 0.9446\n",
      "Epoch 42/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1390 - accuracy: 0.9514 - val_loss: 0.1587 - val_accuracy: 0.9453\n",
      "Epoch 43/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1379 - accuracy: 0.9519 - val_loss: 0.1584 - val_accuracy: 0.9455\n",
      "Epoch 44/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1369 - accuracy: 0.9523 - val_loss: 0.1569 - val_accuracy: 0.9460\n",
      "Epoch 45/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1359 - accuracy: 0.9529 - val_loss: 0.1562 - val_accuracy: 0.9460\n",
      "Epoch 46/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1349 - accuracy: 0.9531 - val_loss: 0.1552 - val_accuracy: 0.9463\n",
      "Epoch 47/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1339 - accuracy: 0.9534 - val_loss: 0.1545 - val_accuracy: 0.9469\n",
      "Epoch 48/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1331 - accuracy: 0.9534 - val_loss: 0.1534 - val_accuracy: 0.9470\n",
      "Epoch 49/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1321 - accuracy: 0.9544 - val_loss: 0.1531 - val_accuracy: 0.9472\n",
      "Epoch 50/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1313 - accuracy: 0.9543 - val_loss: 0.1523 - val_accuracy: 0.9468\n",
      "Epoch 51/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1303 - accuracy: 0.9547 - val_loss: 0.1516 - val_accuracy: 0.9474\n",
      "Epoch 52/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1296 - accuracy: 0.9553 - val_loss: 0.1506 - val_accuracy: 0.9478\n",
      "Epoch 53/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1287 - accuracy: 0.9555 - val_loss: 0.1499 - val_accuracy: 0.9481\n",
      "Epoch 54/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1279 - accuracy: 0.9557 - val_loss: 0.1491 - val_accuracy: 0.9481\n",
      "Epoch 55/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1270 - accuracy: 0.9562 - val_loss: 0.1488 - val_accuracy: 0.9486\n",
      "Epoch 56/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1263 - accuracy: 0.9560 - val_loss: 0.1481 - val_accuracy: 0.9482\n",
      "Epoch 57/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1256 - accuracy: 0.9566 - val_loss: 0.1473 - val_accuracy: 0.9479\n",
      "Epoch 58/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1248 - accuracy: 0.9566 - val_loss: 0.1466 - val_accuracy: 0.9483\n",
      "Epoch 59/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1241 - accuracy: 0.9572 - val_loss: 0.1460 - val_accuracy: 0.9485\n",
      "Epoch 60/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1233 - accuracy: 0.9574 - val_loss: 0.1455 - val_accuracy: 0.9489\n",
      "Epoch 61/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1226 - accuracy: 0.9577 - val_loss: 0.1448 - val_accuracy: 0.9494\n",
      "Epoch 62/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1220 - accuracy: 0.9577 - val_loss: 0.1443 - val_accuracy: 0.9487\n",
      "Epoch 63/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1213 - accuracy: 0.9583 - val_loss: 0.1435 - val_accuracy: 0.9494\n",
      "Epoch 64/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1206 - accuracy: 0.9581 - val_loss: 0.1429 - val_accuracy: 0.9491\n",
      "Epoch 65/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1199 - accuracy: 0.9584 - val_loss: 0.1426 - val_accuracy: 0.9493\n",
      "Epoch 66/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1194 - accuracy: 0.9587 - val_loss: 0.1422 - val_accuracy: 0.9500\n",
      "Epoch 67/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1187 - accuracy: 0.9590 - val_loss: 0.1416 - val_accuracy: 0.9496\n",
      "Epoch 68/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1180 - accuracy: 0.9591 - val_loss: 0.1412 - val_accuracy: 0.9503\n",
      "Epoch 69/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1176 - accuracy: 0.9592 - val_loss: 0.1404 - val_accuracy: 0.9500\n",
      "Epoch 70/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1170 - accuracy: 0.9593 - val_loss: 0.1403 - val_accuracy: 0.9501\n",
      "Epoch 71/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1164 - accuracy: 0.9592 - val_loss: 0.1397 - val_accuracy: 0.9502\n",
      "Epoch 72/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1158 - accuracy: 0.9600 - val_loss: 0.1393 - val_accuracy: 0.9499\n",
      "Epoch 73/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1152 - accuracy: 0.9598 - val_loss: 0.1390 - val_accuracy: 0.9506\n",
      "Epoch 74/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1148 - accuracy: 0.9600 - val_loss: 0.1385 - val_accuracy: 0.9501\n",
      "Epoch 75/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1142 - accuracy: 0.9601 - val_loss: 0.1379 - val_accuracy: 0.9505\n",
      "Epoch 76/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1138 - accuracy: 0.9603 - val_loss: 0.1377 - val_accuracy: 0.9508\n",
      "Epoch 77/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1132 - accuracy: 0.9602 - val_loss: 0.1370 - val_accuracy: 0.9508\n",
      "Epoch 78/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1126 - accuracy: 0.9606 - val_loss: 0.1369 - val_accuracy: 0.9505\n",
      "Epoch 79/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1121 - accuracy: 0.9603 - val_loss: 0.1365 - val_accuracy: 0.9508\n",
      "Epoch 80/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1117 - accuracy: 0.9605 - val_loss: 0.1363 - val_accuracy: 0.9508\n",
      "Epoch 81/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1112 - accuracy: 0.9607 - val_loss: 0.1356 - val_accuracy: 0.9508\n",
      "Epoch 82/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1108 - accuracy: 0.9610 - val_loss: 0.1354 - val_accuracy: 0.9515\n",
      "Epoch 83/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1103 - accuracy: 0.9614 - val_loss: 0.1350 - val_accuracy: 0.9518\n",
      "Epoch 84/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1097 - accuracy: 0.9614 - val_loss: 0.1348 - val_accuracy: 0.9516\n",
      "Epoch 85/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1093 - accuracy: 0.9614 - val_loss: 0.1344 - val_accuracy: 0.9514\n",
      "Epoch 86/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1089 - accuracy: 0.9617 - val_loss: 0.1343 - val_accuracy: 0.9514\n",
      "Epoch 87/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1085 - accuracy: 0.9617 - val_loss: 0.1338 - val_accuracy: 0.9518\n",
      "Epoch 88/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1080 - accuracy: 0.9619 - val_loss: 0.1338 - val_accuracy: 0.9515\n",
      "Epoch 89/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1076 - accuracy: 0.9618 - val_loss: 0.1331 - val_accuracy: 0.9521\n",
      "Epoch 90/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1072 - accuracy: 0.9622 - val_loss: 0.1335 - val_accuracy: 0.9524\n",
      "Epoch 91/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1067 - accuracy: 0.9625 - val_loss: 0.1328 - val_accuracy: 0.9517\n",
      "Epoch 92/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1064 - accuracy: 0.9624 - val_loss: 0.1326 - val_accuracy: 0.9528\n",
      "Epoch 93/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1059 - accuracy: 0.9626 - val_loss: 0.1326 - val_accuracy: 0.9525\n",
      "Epoch 94/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1055 - accuracy: 0.9627 - val_loss: 0.1319 - val_accuracy: 0.9528\n",
      "Epoch 95/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1051 - accuracy: 0.9629 - val_loss: 0.1316 - val_accuracy: 0.9524\n",
      "Epoch 96/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1047 - accuracy: 0.9629 - val_loss: 0.1317 - val_accuracy: 0.9530\n",
      "Epoch 97/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1044 - accuracy: 0.9629 - val_loss: 0.1314 - val_accuracy: 0.9533\n",
      "Epoch 98/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1039 - accuracy: 0.9630 - val_loss: 0.1312 - val_accuracy: 0.9532\n",
      "Epoch 99/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1036 - accuracy: 0.9632 - val_loss: 0.1309 - val_accuracy: 0.9536\n",
      "Epoch 100/100\n",
      "409/409 [==============================] - 1s 2ms/step - loss: 0.1032 - accuracy: 0.9632 - val_loss: 0.1307 - val_accuracy: 0.9527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f9414b6e50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=128, validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
